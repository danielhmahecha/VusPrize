{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#Keras modules\n",
    "import keras.metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Input\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create a confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes =unique_labels(y_true, y_pred)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.grid(b=None)\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "  \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functino to select relevant fields from the csv files\n",
    "def selectFields(df):\n",
    "    new = df.filter(['ada_score','AF','BLOSUM62','codon_degeneracy','Eigen-pred_coding','GERP++_RS', \n",
    "              'integrated_fitCons_score','LoFtool','phyloP100way_vertebrate','SIFT','Consequence'])\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to replace empty values\n",
    "def fillEmpty(df):\n",
    "    df = df.replace({'ada_score': \"-\", 'AF': \"-\", 'Eigen-pred_coding': '-',\n",
    "               'integrated_fitCons_score': '-', 'LoFtool': '-', 'phyloP100way_vertebrate':'-',\n",
    "               'SIFT': '-'}, -1)\n",
    "    df = df.replace({'BLOSUM62':\"-\", 'GERP++_RS':'-'}, 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to split codon degeneracy field\n",
    "def splitCodonDeg (df):\n",
    "    df['codon_degeneracy'] = df['codon_degeneracy'].str.split(',').str[0]\n",
    "    df['Consequence'] = df['Consequence'].str.split(',').str[0]\n",
    "    df = df.replace({'codon_degeneracy':'-'},0)\n",
    "    return df\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinformatic/anaconda3/envs/vusprize/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (6,21) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# Importing datasets\n",
    "ben = pd.read_csv('BEN_2020.txt', sep='\\t')\n",
    "pat = pd.read_csv('PAT_2020.txt', sep='\\t')\n",
    "vus = pd.read_csv('VUS_2020.txt', sep='\\t')\n",
    "ben_exvus = pd.read_csv('EXVUS_BEN_2020.txt', sep='\\t')\n",
    "pat_exvus = pd.read_csv('EXVUS_PAT_2020.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing datasets\n",
    "ben_fields = selectFields(ben)\n",
    "pat_fields = selectFields(pat)\n",
    "vus_fields = selectFields(vus)\n",
    "ben_ex_fields = selectFields(ben_exvus)\n",
    "pat_ex_fields = selectFields(pat_exvus)\n",
    "ben_full = fillEmpty( ben_fields)\n",
    "pat_full = fillEmpty( pat_fields )\n",
    "vus_full = fillEmpty( vus_fields )\n",
    "ben_ex_full = fillEmpty (ben_ex_fields)\n",
    "pat_ex_full = fillEmpty (pat_ex_fields)\n",
    "ben_ok = splitCodonDeg (ben_full)\n",
    "pat_ok = splitCodonDeg (pat_full)\n",
    "vus_ok = splitCodonDeg (vus_full)\n",
    "ben_ex_ok = splitCodonDeg (ben_ex_full)\n",
    "pat_ex_ok = splitCodonDeg (pat_ex_full)\n",
    "ben_ok['CLINSIG']=0\n",
    "pat_ok['CLINSIG']=1\n",
    "set_ok = pd.concat([ben_ok, pat_ok])\n",
    "ben_ex_ok['CLINSIG']=0\n",
    "pat_ex_ok['CLINSIG']=1\n",
    "set_ex_ok= pd.concat([ben_ex_ok,pat_ex_ok])\n",
    "set_dummies=pd.get_dummies(set_ok,columns=['Consequence'])\n",
    "set_ex_dummies=pd.get_dummies(set_ex_ok,columns=['Consequence'])\n",
    "scaler = MinMaxScaler(feature_range=(0, 1), copy=True)\n",
    "scaler.fit(set_dummies)\n",
    "scaler.fit(set_ex_dummies)\n",
    "set_float = set_dummies.astype(float)\n",
    "set_ex_float = set_ex_dummies.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of initial training and testing sets\n",
    "X = set_float.drop(['CLINSIG'],axis=1)\n",
    "y=set_float['CLINSIG']\n",
    "X_train, X_test , y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "X_test.to_csv(r'X_test.csv',index=False)\n",
    "y_test.to_csv(r'y_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Random Forest model\n",
    "rfc=RandomForestClassifier(random_state=2, class_weight = \"balanced\", n_jobs=3)\n",
    "param_grid = { \n",
    "    'n_estimators': [128,256,512,1024],\n",
    "    'max_depth' : [4,7,10,15],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5, scoring='roc_auc')\n",
    "CV_rfc.fit(X_train, y_train)\n",
    "rf_bests=CV_rfc.best_params_\n",
    "clf_RF = RandomForestClassifier(n_jobs=3,n_estimators=rf_bests['n_estimators'], \n",
    "                                max_depth=rf_bests['max_depth'], \n",
    "                                class_weight=\"balanced\",\n",
    "                                random_state=2, \n",
    "                                criterion=rf_bests['criterion'])\n",
    "modelo=clf_RF.fit(X_train,y_train)\n",
    "prediction_RF=clf_RF.predict(X_test)\n",
    "print(classification_report(y_test,prediction_RF))\n",
    "plot_confusion_matrix(y_test, prediction_RF.astype(int), True)\n",
    "plot_confusion_matrix(y_test, prediction_RF.astype(int), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature importances from the RF Model\n",
    "importances = pd.DataFrame(clf_RF.feature_importances_, index=X_train.columns)\n",
    "importances = importances.sort_values(by=[0])\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training SVM model\n",
    "\n",
    "svm_modelo = svm.SVC(probability=True)\n",
    "param_grid = { \n",
    "    'C': [0.1,1,10],\n",
    "    'gamma' : [0.01,0.1,1],\n",
    "    'kernel' :['rbf']\n",
    "}\n",
    "CV_svm = GridSearchCV(estimator=svm_modelo, param_grid=param_grid, cv= 3, scoring='roc_auc')\n",
    "CV_svm.fit(X_train, y_train)\n",
    "best_svm=CV_svm.best_params_\n",
    "svm_modelo = svm.SVC(probability = True, C=best_svm['C'], gamma=best_svm['gamma'],kernel=best_svm['kernel'])\n",
    "svm_modelo.fit(X_train,y_train)\n",
    "prediction_svm=svm_modelo.predict(X_test)\n",
    "print(classification_report(y_test,prediction_svm))\n",
    "plot_confusion_matrix(y_test, prediction_svm.astype(int), True)\n",
    "plot_confusion_matrix(y_test, prediction_svm.astype(int), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create MLP\n",
    "\n",
    "def perceptron_multi(X,y):\n",
    "    perceptron_multicapa = Sequential()\n",
    "    perceptron_multicapa.add(Dense(20, input_dim=X.shape[1], activation='relu'))\n",
    "    perceptron_multicapa.add(Dense(10, input_dim=X.shape[1], activation='relu'))\n",
    "    perceptron_multicapa.add(Dense(10, input_dim=X.shape[1], activation='relu'))\n",
    "    perceptron_multicapa.add(Dense(10, input_dim=X.shape[1], activation='relu'))\n",
    "    perceptron_multicapa.add(Dense(10, input_dim=X.shape[1], activation='relu'))\n",
    "    #perceptron_multicapa.add(Dense(10, activation='relu'))\n",
    "    perceptron_multicapa.add(Dense(1, activation='sigmoid'))\n",
    "    perceptron_multicapa.compile(optimizer='adam',\n",
    "                                 loss='binary_crossentropy',\n",
    "                                 metrics=['accuracy', keras.metrics.Recall()]\n",
    "                                )\n",
    "    perceptron_multicapa.fit(X, y, epochs=25, batch_size=50)\n",
    "    return perceptron_multicapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "60839/60839 [==============================] - 3s 51us/step - loss: 0.2043 - accuracy: 0.9099 - recall_1: 0.8204\n",
      "Epoch 2/25\n",
      "60839/60839 [==============================] - 2s 41us/step - loss: 0.1284 - accuracy: 0.9432 - recall_1: 0.9117\n",
      "Epoch 3/25\n",
      "60839/60839 [==============================] - 2s 39us/step - loss: 0.1255 - accuracy: 0.9438 - recall_1: 0.9093\n",
      "Epoch 4/25\n",
      "60839/60839 [==============================] - 3s 41us/step - loss: 0.1240 - accuracy: 0.9446 - recall_1: 0.9134\n",
      "Epoch 5/25\n",
      "60839/60839 [==============================] - 3s 42us/step - loss: 0.1229 - accuracy: 0.9449 - recall_1: 0.9105\n",
      "Epoch 6/25\n",
      "60839/60839 [==============================] - 2s 36us/step - loss: 0.1218 - accuracy: 0.9447 - recall_1: 0.9135\n",
      "Epoch 7/25\n",
      "60839/60839 [==============================] - 2s 37us/step - loss: 0.1212 - accuracy: 0.9458 - recall_1: 0.9120\n",
      "Epoch 8/25\n",
      "60839/60839 [==============================] - 2s 40us/step - loss: 0.1213 - accuracy: 0.9451 - recall_1: 0.9161\n",
      "Epoch 9/25\n",
      "60839/60839 [==============================] - 3s 42us/step - loss: 0.1206 - accuracy: 0.9449 - recall_1: 0.9131\n",
      "Epoch 10/25\n",
      "60839/60839 [==============================] - 2s 38us/step - loss: 0.1209 - accuracy: 0.9461 - recall_1: 0.9159\n",
      "Epoch 11/25\n",
      "60839/60839 [==============================] - 2s 38us/step - loss: 0.1203 - accuracy: 0.9463 - recall_1: 0.9177\n",
      "Epoch 12/25\n",
      "42700/60839 [====================>.........] - ETA: 0s - loss: 0.1176 - accuracy: 0.9471 - recall_1: 0.9190"
     ]
    }
   ],
   "source": [
    "#Training MLP model\n",
    "red_modelo = perceptron_multi(X_train, y_train.astype(float))\n",
    "plot_confusion_matrix(y_test, red_modelo.predict_classes(X_test).astype(int), True)\n",
    "plot_confusion_matrix(y_test, red_modelo.predict_classes(X_test).astype(int), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model ROCs\n",
    "\n",
    "score_RF=clf_RF.predict_proba(X_test)\n",
    "score_RF\n",
    "fpr_RF, tpr_RF, threshs = metrics.roc_curve(y_test,score_RF[:,1])\n",
    "roc_auc_RF= auc(fpr_RF, tpr_RF)\n",
    "\n",
    "score_SVM=svm_modelo.predict_proba(X_test)\n",
    "score_SVM\n",
    "fpr_SVM, tpr_SVM, threshs = metrics.roc_curve(y_test,score_SVM[:,1])\n",
    "roc_auc_SVM= auc(fpr_SVM, tpr_SVM)\n",
    "\n",
    "red_probas = red_modelo.predict_proba(X_test)\n",
    "fpr_MLP, tpr_MLP, threshs = metrics.roc_curve(y_test, red_probas)\n",
    "roc_auc_mlp= auc(fpr_MLP, tpr_MLP)\n",
    "\n",
    "#fpr_CADD, tpr_CADD, threshs= metrics.roc_curve(y_test,X_test['CADD_PHRED'])\n",
    "#roc_auc_CADD= auc(fpr_CADD, tpr_CADD)\n",
    "#plt.close('all')\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "lw = 2\n",
    "\n",
    "plt.plot(fpr_RF,tpr_RF,\n",
    "         lw=5, label='Random Forest (area = %0.2f)' % roc_auc_RF)\n",
    "plt.plot(fpr_SVM,tpr_SVM, \n",
    "         lw=5, label='SVM (area = %0.2f)' % roc_auc_SVM)\n",
    "plt.plot(fpr_MLP, tpr_MLP, \n",
    "         lw=5, label='MLP (area = %0.2f)' % roc_auc_mlp)\n",
    "plt.plot(fpr_dt, tpr_dt, \n",
    "        lw=5, label='Decision Tree (area = %0.2f)' % roc_auc_dt)\n",
    "plt.plot(fpr_nb, tpr_nb, \n",
    "        lw=5, label='Naive Bayes(area = %0.2f)' % roc_auc_nb)\n",
    "#plt.plot(fpr_CADD, tpr_CADD,\n",
    "#         lw=lw, label='CADD (area = %0.2f)' % roc_auc_CADD)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=30)\n",
    "plt.ylabel('True Positive Rate',fontsize=30)\n",
    "plt.title('ROCs - Pathogenicity Prediction VUS - All Variant Types',fontsize=30)\n",
    "plt.legend(fontsize=22,loc='center left', bbox_to_anchor=(1, 0.5),framealpha=1,frameon=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Model ROCs - \"missense\" variants only\n",
    "\n",
    "both = X_test\n",
    "both['CLINSIG']=y_test\n",
    "both_miss = both[both['Consequence_missense_variant']==1]\n",
    "X_miss = both_miss.drop(['CLINSIG'],axis=1)\n",
    "y_miss = both_miss['CLINSIG']\n",
    "\n",
    "score_RF_miss=clf_RF.predict_proba(X_miss)\n",
    "score_RF_miss\n",
    "fpr_RF_miss, tpr_RF_miss, threshs = metrics.roc_curve(y_miss,score_RF_miss[:,1])\n",
    "roc_auc_RF_miss= auc(fpr_RF_miss, tpr_RF_miss)\n",
    "\n",
    "score_SVM_miss=svm_modelo.predict_proba(X_miss)\n",
    "score_SVM_miss\n",
    "fpr_SVM_miss, tpr_SVM_miss, threshs = metrics.roc_curve(y_miss,score_SVM_miss[:,1])\n",
    "roc_auc_SVM_miss= auc(fpr_SVM_miss, tpr_SVM_miss)\n",
    "\n",
    "red_probas_miss = red_modelo.predict_proba(X_miss)\n",
    "fpr_MLP_miss, tpr_MLP_miss, thresholds = metrics.roc_curve(y_miss, red_probas_miss)\n",
    "roc_auc_mlp_miss= auc(fpr_MLP_miss, tpr_MLP_miss)\n",
    "\n",
    "#fpr_CADD_miss, tpr_CADD_miss, threshs= metrics.roc_curve(y_miss,X_miss['CADD_PHRED'])\n",
    "#roc_auc_CADD_miss= auc(fpr_CADD_miss, tpr_CADD_miss)\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "lw = 2\n",
    "\n",
    "plt.plot(fpr_RF_miss,tpr_RF_miss, color='darkred',\n",
    "         lw=5, label='Random Forest (area = %0.2f)' % roc_auc_RF_miss)\n",
    "plt.plot(fpr_SVM_miss,tpr_SVM_miss, color='seagreen',\n",
    "         lw=5, label='SVM (area = %0.2f)' % roc_auc_SVM_miss)\n",
    "plt.plot(fpr_MLP_miss, tpr_MLP_miss, color='black',\n",
    "         lw=5, label='MLP (area = %0.2f)' % roc_auc_mlp_miss)\n",
    "plt.plot([0, 1], [0, 1], color='royalblue', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate',fontsize=30)\n",
    "plt.ylabel('True Positive Rate',fontsize=30)\n",
    "plt.title('ROCs - Pathogenicity Prediction VUS - Missense Variants Only',fontsize=30)\n",
    "plt.legend(fontsize=22,loc='center left', bbox_to_anchor=(1, 0.5),framealpha=1,frameon=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking with the ex VUS set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to replace all empty fields\n",
    "def fillAll(df):\n",
    "    df = df.replace(\"-\",0)\n",
    "    df = df.replace(\".\",0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to complete columns from the exVUS set\n",
    "def completeColumns (df):\n",
    "    consequences = ['Consequence_3_prime_UTR_variant',\n",
    "       'Consequence_5_prime_UTR_variant',\n",
    "       'Consequence_TF_binding_site_variant',\n",
    "       'Consequence_downstream_gene_variant', 'Consequence_frameshift_variant',\n",
    "       'Consequence_inframe_deletion', 'Consequence_inframe_insertion',\n",
    "       'Consequence_intergenic_variant', 'Consequence_intron_variant',\n",
    "       'Consequence_missense_variant',\n",
    "       'Consequence_non_coding_transcript_exon_variant',\n",
    "       'Consequence_protein_altering_variant',\n",
    "       'Consequence_regulatory_region_variant',\n",
    "       'Consequence_splice_acceptor_variant',\n",
    "       'Consequence_splice_donor_variant', 'Consequence_splice_region_variant',\n",
    "       'Consequence_start_lost', 'Consequence_stop_gained',\n",
    "       'Consequence_stop_lost', 'Consequence_stop_retained_variant',\n",
    "       'Consequence_synonymous_variant', 'Consequence_upstream_gene_variant']\n",
    "    for c in consequences:\n",
    "        try:\n",
    "            df[c]\n",
    "        except:\n",
    "            df[c] = 0\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process ex VUS sets\n",
    "ben_ex = ben_exvus\n",
    "pat_ex = pat_exvus\n",
    "ben_ex['CLINSIG'] = 0\n",
    "pat_ex['CLINSIG'] = 1\n",
    "set_ex_all = pd.concat([ben_ex, pat_ex])\n",
    "set_ex_all_filter = selectFields (set_ex_all)\n",
    "set_ex_all_fill = fillEmpty(set_ex_all_filter)\n",
    "set_ex_all_split = splitCodonDeg (set_ex_all_fill)\n",
    "set_ex_all_dummies =pd.get_dummies(set_ex_all_split,columns=['Consequence'])\n",
    "set_ex_all_complete = completeColumns(set_ex_all_dummies) \n",
    "scaler = MinMaxScaler(feature_range=(0, 1), copy=True)\n",
    "scaler.fit(set_ex_all_complete)\n",
    "X_ex = set_ex_all_complete.astype(float) \n",
    "y_ex = set_ex_all['CLINSIG']\n",
    "\n",
    "set_ex_all_tools=set_ex_all.filter(['DANN_score','Eigen-pred_coding','LRT_score','M-CAP_score',\n",
    "                                          'MetaLR_score','MetaSVM_score',\n",
    "                                          'MutPred_score','PolyPhen','REVEL_score','SIFT',\n",
    "                                          'ada_score', 'rf_score', 'CADD_PHRED'])\n",
    "set_ex_all_filled=fillAll(set_ex_all_tools)\n",
    "tools_scores = set_ex_all_filled.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create ROCS from scores\n",
    "def carlROC(column):\n",
    "    fpr, tpr, threshs= metrics.roc_curve(y_ex,tools_scores[column])\n",
    "    roc_auc= auc(fpr, tpr)\n",
    "    values = {'roc_auc': roc_auc, 'fpr': fpr, 'tpr': tpr}\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of ROC values from scores\n",
    "values_DANN= carlROC('DANN_score')\n",
    "values_Eigen= carlROC('Eigen-pred_coding')\n",
    "values_LRT= carlROC('LRT_score')\n",
    "values_MCAP= carlROC('M-CAP_score')\n",
    "values_MetaLR= carlROC('MetaLR_score')\n",
    "values_MetaSVM= carlROC('MetaSVM_score')\n",
    "values_MutPred= carlROC('MutPred_score')\n",
    "values_PolyPhen= carlROC('PolyPhen')\n",
    "values_Revel= carlROC('REVEL_score')\n",
    "values_Sift= carlROC('SIFT')\n",
    "values_ada= carlROC('ada_score')\n",
    "values_rf= carlROC('rf_score')\n",
    "values_CADD= carlROC('CADD_PHRED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of ROC plots \n",
    "score_RF_ex=clf_RF.predict_proba(X_ex)\n",
    "score_RF_ex\n",
    "fpr_RF_ex, tpr_RF_ex, threshs = metrics.roc_curve(y_ex,score_RF_ex[:,1])\n",
    "roc_auc_RF_ex= auc(fpr_RF_ex, tpr_RF_ex)\n",
    "\n",
    "score_SVM_ex=svm_modelo.predict_proba(X_ex)\n",
    "score_SVM_ex\n",
    "fpr_SVM_ex, tpr_SVM_ex, threshs = metrics.roc_curve(y_ex,score_SVM_ex[:,1])\n",
    "roc_auc_SVM_ex= auc(fpr_SVM_ex, tpr_SVM_ex)\n",
    "\n",
    "red_probas_ex = red_modelo.predict_proba(X_ex)\n",
    "fpr_MLP_ex, tpr_MLP_ex, thresholds = metrics.roc_curve(y_ex, red_probas_ex)\n",
    "roc_auc_mlp_ex= auc(fpr_MLP_ex, tpr_MLP_ex)\n",
    "plt.close('all')\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "lw = 2\n",
    "\n",
    "plt.plot(fpr_RF_ex,tpr_RF_ex,\n",
    "         lw=5, label='Random Forest (area = %0.2f)' % roc_auc_RF_ex)\n",
    "plt.plot(fpr_SVM_ex,tpr_SVM_ex,\n",
    "         lw=5, label='SVM (area = %0.2f)' % roc_auc_SVM_ex)\n",
    "plt.plot(fpr_MLP_ex, tpr_MLP_ex, \n",
    "         lw=5, label='MLP (area = %0.2f)' % roc_auc_mlp_ex)\n",
    "#plt.plot(fpr_dt_ex, tpr_dt_ex, color='peru', \n",
    "#        lw=5, label='Decision Tree (area = %0.2f)' % roc_auc_dt_ex)\n",
    "#plt.plot(fpr_nb_ex, tpr_nb_ex, color='gray', \n",
    "#        lw=5, label='Naive Bayes(area = %0.2f)' % roc_auc_nb_ex)\n",
    "plt.plot(values_CADD['fpr'], values_CADD['tpr'], \n",
    "         lw=lw, label='CADD (area = %0.2f)' % values_CADD['roc_auc'])\n",
    "\n",
    "#LRT_area = 1-values_LRT['roc_auc']\n",
    "#plt.plot(1-values_LRT['fpr'],1- values_LRT['tpr'], color='cadetblue',\n",
    "#         lw=lw, label='LRT (area = %0.2f)' % LRT_area)\n",
    "#plt.plot(values_MCAP['fpr'], values_MCAP['tpr'], color='sandybrown',\n",
    "#         lw=lw, label='M-CAP (area = %0.2f)' % values_MCAP['roc_auc'])\n",
    "#plt.plot(values_Eigen['fpr'], values_Eigen['tpr'], color='teal',\n",
    "#         lw=lw, label='Eigen (area = %0.2f)' % values_Eigen['roc_auc'])\n",
    "#plt.plot(values_MetaLR['fpr'], values_MetaLR['tpr'], color='tan',\n",
    "#         lw=lw, label='MetaLR (area = %0.2f)' % values_MetaLR['roc_auc'])\n",
    "#plt.plot(values_MetaSVM['fpr'], values_MetaSVM['tpr'], color='indianred',\n",
    "#         lw=lw, label='MetaSVM(area = %0.2f)' % values_MetaSVM['roc_auc'])\n",
    "#plt.plot(values_MutPred['fpr'], values_MutPred['tpr'], color='fuchsia',\n",
    "#         lw=lw, label='MutPred(area = %0.2f)' % values_MutPred['roc_auc'])\n",
    "plt.plot(values_Revel['fpr'], values_Revel['tpr'], \n",
    "         lw=lw, label='REVEL (area = %0.2f)' % values_Revel['roc_auc'])\n",
    "#SIFT_area = 1-values_Sift['roc_auc']\n",
    "#plt.plot(values_Sift['tpr'], values_Sift['fpr'], color='navy',\n",
    "#         lw=lw, label='SIFT (area = %0.2f)' % SIFT_area)\n",
    "plt.plot(values_PolyPhen['fpr'], values_PolyPhen['tpr'], \n",
    "         lw=lw, label='PolyPhen (area = %0.2f)' % values_PolyPhen['roc_auc'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='royalblue', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate',fontsize=34)\n",
    "plt.ylabel('True Positive Rate',fontsize=34)\n",
    "plt.title('All types (n=5526)',fontsize=34)\n",
    "plt.legend(fontsize=28,framealpha=1,frameon=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing of ex vus information from prediciton tools\n",
    "set_ex_all_tools = splitCodonDeg (set_ex_all)\n",
    "set_ex_all_dummies_tools =pd.get_dummies(set_ex_all_tools,columns=['Consequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter relevant columns\n",
    "def filterColumns(df):\n",
    "    df = df.filter(['APPRIS','BLOSUM62', 'CADD_PHRED', 'CADD_RAW',\n",
    "       'CADD_phred',  'CLINSIG', 'DANN_score', 'Eigen-pred_coding',\n",
    "       'FATHMM_score',  'GERP++_RS', 'LINSIGHT', 'LRT_score',\n",
    "       'LoFtool','M-CAP_score', 'MANE', 'MPC_score', 'MVP_score', 'MaxEntScan_alt',\n",
    "       'MaxEntScan_diff', 'MaxEntScan_ref', 'MetaLR_score', 'MetaSVM_score',\n",
    "       'MutPred_score',  'MutationTaster_score', 'MutationAssessor_score',\n",
    "       'PROVEAN_score', 'PolyPhen',  'REVEL_score', 'SIFT', \n",
    "       'TSL', 'VEST4_score', 'ada_score'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to process relevant columns\n",
    "def process (df):\n",
    "    df = filterColumns(df)\n",
    "    df['MutationAssessor_score'] = df['MutationAssessor_score'].str.split(',').str[0]\n",
    "    df['MutationTaster_score'] = df['MutationTaster_score'].str.split(',').str[0]\n",
    "    df['PROVEAN_score'] = df['PROVEAN_score'].str.split(',').str[0]\n",
    "    df['VEST4_score'] = df['VEST4_score'].str.split(',').str[0]\n",
    "    df['FATHMM_score'] = df['FATHMM_score'].str.split(',').str[0]\n",
    "    df['GERP++_RS'] = df['GERP++_RS'].str.split(',').str[0]\n",
    "    df['MPC_score'] = df['MPC_score'].str.split(',').str[0]\n",
    "    df['MVP_score'] = df['MVP_score'].str.split(',').str[0]\n",
    "    df = fillAll(df)\n",
    "    df = completeColumns(df)\n",
    "    df.head()\n",
    "    X = df.astype (float)\n",
    "    y = df['CLINSIG'].astype(float)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1), copy=True)\n",
    "    scaler.fit (X)\n",
    "    return [X,y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to process dataset to test model\n",
    "def processModel(df):\n",
    "    df = df.filter(['ada_score','AF','BLOSUM62','codon_degeneracy','Eigen-pred_coding','GERP++_RS', \n",
    "              'integrated_fitCons_score','LoFtool','phyloP100way_vertebrate','SIFT', 'Consequence_5_prime_UTR_variant',\n",
    "              'Consequence_downstream_gene_variant', 'Consequence_frameshift_variant',\n",
    "              'Consequence_inframe_deletion', 'Consequence_inframe_insertion',\n",
    "              'Consequence_intron_variant', 'Consequence_missense_variant',\n",
    "              'Consequence_non_coding_transcript_exon_variant',\n",
    "              'Consequence_splice_donor_variant', 'Consequence_splice_region_variant',\n",
    "              'Consequence_start_lost', 'Consequence_stop_gained',\n",
    "              'Consequence_synonymous_variant', 'Consequence_upstream_gene_variant',\n",
    "              'Consequence_intergenic_variant'])\n",
    "    df = df.replace({'ada_score': \"-\", 'AF': \"-\", 'Eigen-pred_coding': '-',\n",
    "               'integrated_fitCons_score': '-', 'LoFtool': '-', 'phyloP100way_vertebrate':'-',\n",
    "               'SIFT': '-'}, -1)\n",
    "    df = df.replace({'BLOSUM62':\"-\", 'GERP++_RS':'-'}, 0)\n",
    "    #df['codon_degeneracy'] = df['codon_degeneracy'].str.split(',').str[0]\n",
    "    df = df.replace({'codon_degeneracy':'-'},0)\n",
    "    df = completeColumns(df)\n",
    "    df = df.astype(float)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1), copy=True)\n",
    "    scaler.fit (df)\n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creation of subsets of different data types\n",
    "\n",
    "#Missense variants\n",
    "set_ex_miss = set_ex_all_dummies_tools[set_ex_all_dummies_tools['Consequence_missense_variant']==1]\n",
    "X_miss = process(set_ex_miss)[0]\n",
    "miss =  processModel(set_ex_miss)\n",
    "miss = completeColumns(miss)\n",
    "y_miss = process(set_ex_miss)[1]\n",
    "\n",
    "##Synonymous variants\n",
    "set_ex_syn = set_ex_all_dummies_tools[set_ex_all_dummies_tools['Consequence_synonymous_variant']==1]\n",
    "X_syn= process(set_ex_syn)[0]\n",
    "syn =  processModel(set_ex_syn)\n",
    "syn = completeColumns(syn)\n",
    "y_syn = process(set_ex_syn)[1]\n",
    "\n",
    "#Non coding exon variants\n",
    "set_ex_nce = set_ex_all_dummies_tools[set_ex_all_dummies_tools['Consequence_non_coding_transcript_exon_variant']==1]\n",
    "X_nce= process(set_ex_nce)[0]\n",
    "nce =  processModel(set_ex_nce)\n",
    "nce = completeColumns(nce)\n",
    "y_nce = process(set_ex_nce)[1]\n",
    "\n",
    "#Intron type variants\n",
    "set_ex_int = set_ex_all_dummies_tools[set_ex_all_dummies_tools['Consequence_intron_variant']==1]\n",
    "X_int= process(set_ex_int)[0]\n",
    "vint =  processModel(set_ex_int)\n",
    "vint = completeColumns (vint)\n",
    "y_int = process(set_ex_int)[1]\n",
    "\n",
    "#Splice variants \n",
    "set_ex_spl = set_ex_all_dummies_tools[(set_ex_all_dummies_tools['Consequence_splice_donor_variant']==1)\n",
    "                                     | (set_ex_all_dummies_tools['Consequence_splice_region_variant']==1)]\n",
    "X_spl= process(set_ex_spl)[0]\n",
    "spl =  processModel(set_ex_spl)\n",
    "spl = completeColumns(spl)\n",
    "y_spl = process(set_ex_spl)[1]\n",
    "\n",
    "#Other variant types\n",
    "set_ex_oth =  set_ex_all_dummies_tools[(set_ex_all_dummies_tools['Consequence_splice_donor_variant']!=1)\n",
    "                                     & (set_ex_all_dummies_tools['Consequence_splice_region_variant']!=1)\n",
    "                                     & (set_ex_all_dummies_tools['Consequence_missense_variant']!=1)\n",
    "                                     & (set_ex_all_dummies_tools['Consequence_synonymous_variant']!=1)  \n",
    "                                     & (set_ex_all_dummies_tools['Consequence_non_coding_transcript_exon_variant']!=1)\n",
    "                                     & (set_ex_all_dummies_tools['Consequence_intron_variant']!=1)\n",
    "                                     & (set_ex_all_dummies_tools['Consequence_frameshift_variant']!=1)\n",
    "                                     & (set_ex_all_dummies_tools['Consequence_inframe_deletion']!=1)\n",
    "                                     & (set_ex_all_dummies_tools['Consequence_inframe_insertion']!=1)\n",
    "                                     & (set_ex_all_dummies_tools['Consequence_intergenic_variant']!=1)]\n",
    "\n",
    "X_oth= process(set_ex_oth)[0]\n",
    "oth =  processModel(set_ex_oth)\n",
    "oth = completeColumns(oth)\n",
    "y_oth = process(set_ex_oth)[1]\n",
    "\n",
    "#Insertion or deletion variants\n",
    "set_ex_indl = set_ex_all_dummies_tools[(set_ex_all_dummies_tools['Consequence_frameshift_variant']==1)\n",
    "                                      | (set_ex_all_dummies_tools['Consequence_inframe_deletion']==1)\n",
    "                                      | (set_ex_all_dummies_tools['Consequence_inframe_insertion']==1)]\n",
    "X_indl= process(set_ex_indl)[0]\n",
    "indl =  processModel(set_ex_indl)\n",
    "indl = completeColumns(indl)\n",
    "y_indl = process(set_ex_indl)[1]\n",
    "\n",
    "#Intergenic region variants\n",
    "set_ex_ign = set_ex_all_dummies_tools[(set_ex_all_dummies_tools['Consequence_intergenic_variant']==1)]\n",
    "X_ign= process(set_ex_ign)[0]\n",
    "ign =  processModel(set_ex_ign)\n",
    "ign = completeColumns(ign)\n",
    "y_ign = process(set_ex_ign)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create ROC values for specific type of variants\n",
    "def carlROC_specific(X,y,column):\n",
    "    fpr, tpr, threshs= metrics.roc_curve(y,X[column])\n",
    "    roc_auc= auc(fpr, tpr)\n",
    "    values = {'roc_auc': roc_auc, 'fpr': fpr, 'tpr': tpr, 'threshs': threshs}\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotValues(tool, X,y,consType,num):\n",
    "    #score_nb=clf_nb.predict_proba(tool)\n",
    "    #fpr_nb, tpr_nb, threshs = metrics.roc_curve(y,score_nb[:,1])\n",
    "    #roc_auc_nb= auc(fpr_nb, tpr_nb)\n",
    "\n",
    "    #score_dt=clf_dt.predict_proba(tool)\n",
    "    #fpr_dt, tpr_dt, threshs = metrics.roc_curve(y,score_dt[:,1])\n",
    "    #roc_auc_dt= auc(fpr_dt, tpr_dt)\n",
    "\n",
    "    score_RF=clf_RF.predict_proba(tool)\n",
    "    score_RF\n",
    "    fpr_RF, tpr_RF, threshs = metrics.roc_curve(y,score_RF[:,1])\n",
    "    roc_auc_RF= auc(fpr_RF, tpr_RF)\n",
    "\n",
    "    score_SVM=svm_modelo.predict_proba(tool)\n",
    "    score_SVM\n",
    "    fpr_SVM, tpr_SVM, threshs = metrics.roc_curve(y,score_SVM[:,1])\n",
    "    roc_auc_SVM= auc(fpr_SVM, tpr_SVM)\n",
    "\n",
    "    red_probas = red_modelo.predict_proba(tool)\n",
    "    fpr_MLP, tpr_MLP, thresholds = metrics.roc_curve(y, red_probas)\n",
    "    roc_auc_mlp= auc(fpr_MLP, tpr_MLP)\n",
    "    \n",
    "   \n",
    "    \n",
    "    plt.close('all')\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    #plt.style.use('seaborn-paper')\n",
    "    lw = 2\n",
    "    plt.plot(fpr_RF,tpr_RF, \n",
    "             lw=5, label='Random Forest (area = %0.2f)' % roc_auc_RF)\n",
    "    plt.plot(fpr_SVM,tpr_SVM, \n",
    "             lw=5, label='SVM (area = %0.2f)' % roc_auc_SVM)\n",
    "    plt.plot(fpr_MLP, tpr_MLP, \n",
    "             lw=5, label='MLP (area = %0.2f)' % roc_auc_mlp)\n",
    "    #plt.plot(fpr_dt, tpr_dt, color='peru', \n",
    "            #lw=5, label='Decision Tree (area = %0.2f)' % roc_auc_dt)\n",
    "    #plt.plot(fpr_nb, tpr_nb, color='gray', \n",
    "            #lw=5, label='Naive Bayes(area = %0.2f)' % roc_auc_nb)\n",
    "    \n",
    "    \n",
    "    #plt.plot(carlROC_specific(X,y,'APPRIS')['fpr'], carlROC_specific(X,y,'APPRIS')['tpr'] , color='olive', lw=lw, label='APPRIS, (area = %0.2f)' % carlROC_specific(X,y,'APPRIS')['roc_auc'])\n",
    "\n",
    "    #plt.plot(carlROC_specific(X,y,'BLOSUM62')['fpr'], carlROC_specific(X,y,'BLOSUM62')['tpr'] , color='olive', lw=lw, linestyle=\"--\", label='BLOSUM62, (area = %0.2f)' % carlROC_specific(X,y,'BLOSUM62')['roc_auc'])\n",
    "\n",
    "    plt.plot(carlROC_specific(X,y,'CADD_PHRED')['fpr'], carlROC_specific(X,y,'CADD_PHRED')['tpr'] , label='CADD (area = %0.2f)' % carlROC_specific(X,y,'CADD_PHRED')['roc_auc'])\n",
    "    #plt.plot(carlROC_specific(X,y,'CADD_RAW')['fpr'], carlROC_specific(X,y,'CADD_RAW')['tpr'] , color='teal', lw=lw, linestyle=\"--\",label='CADD_RAW, (area = %0.2f)' % carlROC_specific(X,y,'CADD_RAW')['roc_auc']) \n",
    "\n",
    "    #plt.plot(carlROC_specific(X,y,'CADD_phred')['fpr'], carlROC_specific(X,y,'CADD_phred')['tpr'] , color='tan', lw=lw, label='CADD_phred, (area = %0.2f)' % carlROC_specific(X,y,'CADD_phred')['roc_auc'])\n",
    "\n",
    "    #plt.plot(carlROC_specific(X,y,'CLINSIG')['fpr'], carlROC_specific(X,y,'CLINSIG')['tpr'] , color='tan', lw=lw,linestyle=\"--\", label='CLINSIG, (area = %0.2f)' % carlROC_specific(X,y,'CLINSIG')['roc_auc'])\n",
    "\n",
    "    #plt.plot(carlROC_specific(X,y,'DANN_score')['fpr'], carlROC_specific(X,y,'DANN_score')['tpr'] , color='indianred', lw=lw, label='DANN_score, (area = %0.2f)' % carlROC_specific(X,y,'DANN_score')['roc_auc'])\n",
    "\n",
    "    #plt.plot(carlROC_specific(X,y,'Eigen-pred_coding')['fpr'], carlROC_specific(X,y,'Eigen-pred_coding')['tpr'] , lw=lw, label='Eigen (area = %0.2f)' % carlROC_specific(X,y,'Eigen-pred_coding')['roc_auc'])\n",
    "\n",
    "    #plt.plot(carlROC_specific(X,y,'FATHMM_score')['fpr'], carlROC_specific(X,y,'FATHMM_score')['tpr'] , color='orangered', lw=lw, label='FATHMM_score, (area = %0.2f)' % carlROC_specific(X,y,'FATHMM_score')['roc_auc'])\n",
    "\n",
    "    #plt.plot(carlROC_specific(X,y,'GERP++_RS')['fpr'], carlROC_specific(X,y,'GERP++_RS')['tpr'] , color='orangered', lw=lw, linestyle=\"--\",label='GERP++_RS, (area = %0.2f)' % carlROC_specific(X,y,'GERP++_RS')['roc_auc'])\n",
    "\n",
    "    #plt.plot(carlROC_specific(X,y,'LINSIGHT')['fpr'], carlROC_specific(X,y,'LINSIGHT')['tpr'] , color='saddlebrown', lw=lw, label='LINSIGHT, (area = %0.2f)' % carlROC_specific(X,y,'LINSIGHT')['roc_auc'])\n",
    "\n",
    "    #plt.plot((1-carlROC_specific(X,y,'LRT_score')['fpr']), (1-carlROC_specific(X,y,'LRT_score')['tpr']) , color='saddlebrown', lw=lw, linestyle=\"--\",label='LRT_score, (area = %0.2f)' % (1-carlROC_specific(X,y,'LRT_score')['roc_auc']))\n",
    "\n",
    "    #plt.plot(carlROC_specific(X,y,'LoFtool')['fpr'], carlROC_specific(X,y,'LoFtool')['tpr'] , color='orange', lw=lw, label='LoFtool, (area = %0.2f)' % carlROC_specific(X,y,'LoFtool')['roc_auc']) \n",
    "\n",
    "    #plt.plot(carlROC_specific(X,y,'M-CAP_score')['fpr'], carlROC_specific(X,y,'M-CAP_score')['tpr'] , lw=lw, label='M-CAP (area = %0.2f)' % carlROC_specific(X,y,'M-CAP_score')['roc_auc'])\n",
    "\n",
    "    #plt.plot(carlROC_specific(X,y,'MANE')['fpr'], carlROC_specific(X,y,'MANE')['tpr'] , color='gold', lw=lw, label='MANE, (area = %0.2f)' % carlROC_specific(X,y,'MANE')['roc_auc']) \n",
    "\n",
    "    #plt.plot(carlROC_specific(X,y,'MPC_score')['fpr'], carlROC_specific(X,y,'MPC_score')['tpr'] , color='gold', lw=lw, linestyle=\"--\",label='MPC_score, (area = %0.2f)' % carlROC_specific(X,y,'MPC_score')['roc_auc']) \n",
    "\n",
    "    #plt.plot(carlROC_specific(X,y,'MVP_score')['fpr'], carlROC_specific(X,y,'MVP_score')['tpr'] , color='lawngreen', lw=lw, label='MVP_score, (area = %0.2f)' % carlROC_specific(X,y,'MVP_score')['roc_auc']) \n",
    "\n",
    "    #plt.plot(carlROC_specific(X,y,'MaxEntScan_alt')['fpr'], carlROC_specific(X,y,'MaxEntScan_alt')['tpr'] , color='lawngreen', lw=lw, linestyle=\"--\",label='MaxEntScan_alt, (area = %0.2f)' % carlROC_specific(X,y,'MaxEntScan_alt')['roc_auc']) \n",
    "\n",
    "    #plt.plot(carlROC_specific(X,y,'MaxEntScan_diff')['fpr'], carlROC_specific(X,y,'MaxEntScan_diff')['tpr'] , lw=lw, label='MaxEntScan_diff, (area = %0.2f)' % carlROC_specific(X,y,'MaxEntScan_diff')['roc_auc']) \n",
    "\n",
    "    #plt.plot(carlROC_specific(X,y,'MaxEntScan_ref')['fpr'], carlROC_specific(X,y,'MaxEntScan_ref')['tpr'] , color='palegreen', lw=lw, linestyle=\"--\",label='MaxEntScan_ref, (area = %0.2f)' % carlROC_specific(X,y,'MaxEntScan_ref')['roc_auc']) \n",
    "\n",
    "    #plt.plot(carlROC_specific(X,y,'MetaLR_score')['fpr'], carlROC_specific(X,y,'MetaLR_score')['tpr'] ,  lw=lw, label='MetaLR_score, (area = %0.2f)' % carlROC_specific(X,y,'MetaLR_score')['roc_auc']) \n",
    "\n",
    "    #plt.plot(carlROC_specific(X,y,'MetaSVM_score')['fpr'], carlROC_specific(X,y,'MetaSVM_score')['tpr'] ,  lw=lw, label='MetaSVM_score, (area = %0.2f)' % carlROC_specific(X,y,'MetaSVM_score')['roc_auc'])\n",
    "\n",
    "    #plt.plot(carlROC_specific(X,y,'MutPred_score')['fpr'], carlROC_specific(X,y,'MutPred_score')['tpr'] , color='turquoise', lw=lw, label='MutPred_score, (area = %0.2f)' % carlROC_specific(X,y,'MutPred_score')['roc_auc'])\n",
    "\n",
    "    #plt.plot(carlROC_specific(X,y,'MutationTaster_score')['fpr'], carlROC_specific(X,y,'MutationTaster_score')['tpr'] , color='turquoise', lw=lw, linestyle=\"--\",label='MutationTaster_score, (area = %0.2f)' % carlROC_specific(X,y,'MutationTaster_score')['roc_auc']) \n",
    "\n",
    "    #plt.plot(carlROC_specific(X,y,'MutationAssessor_score')['fpr'], carlROC_specific(X,y,'MutationAssessor_score')['tpr'] , color='steelblue', lw=lw, label='MutationAssessor_score, (area = %0.2f)' % carlROC_specific(X,y,'MutationAssessor_score')['roc_auc'])\n",
    "\n",
    "    #plt.plot(carlROC_specific(X,y,'PROVEAN_score')['fpr'], carlROC_specific(X,y,'PROVEAN_score')['tpr'] , color='steelblue', lw=lw,linestyle=\"--\", label='PROVEAN_score, (area = %0.2f)' % carlROC_specific(X,y,'PROVEAN_score')['roc_auc'])\n",
    "\n",
    "    #plt.plot(carlROC_specific(X,y,'PolyPhen')['fpr'], carlROC_specific(X,y,'PolyPhen')['tpr'] ,  lw=lw, label='PolyPhen (area = %0.2f)' % carlROC_specific(X,y,'PolyPhen')['roc_auc'])\n",
    "\n",
    "    #plt.plot(carlROC_specific(X,y,'REVEL_score')['fpr'], carlROC_specific(X,y,'REVEL_score')['tpr'] ,  lw=lw, label='REVEL_score (area = %0.2f)' % carlROC_specific(X,y,'REVEL_score')['roc_auc'])\n",
    "\n",
    "    #plt.plot((1-carlROC_specific(X,y,'SIFT')['fpr']), (1-carlROC_specific(X,y,'SIFT')['tpr'] ),  lw=lw, label='SIFT (area = %0.2f)' % (1-carlROC_specific(X,y,'SIFT')['roc_auc']))\n",
    "\n",
    "    #plt.plot(carlROC_specific(X,y,'TSL')['fpr'], carlROC_specific(X,y,'TSL')['tpr'] , color='crimson', lw=lw, linestyle=\"--\",label='TSL, (area = %0.2f)' % carlROC_specific(X,y,'TSL')['roc_auc'])\n",
    "\n",
    "    #plt.plot(carlROC_specific(X,y,'VEST4_score')['fpr'], carlROC_specific(X,y,'VEST4_score')['tpr'] , color='blue', lw=lw, linestyle=\"--\",label='VEST4_score, (area = %0.2f)' % carlROC_specific(X,y,'VEST4_score')['roc_auc']) \n",
    "\n",
    "    #plt.plot(carlROC_specific(X,y,'ada_score')['fpr'], carlROC_specific(X,y,'ada_score')['tpr'] , lw=lw, label='ada score (area = %0.2f)' % carlROC_specific(X,y,'ada_score')['roc_auc']) \n",
    "\n",
    "    #plt.plot([0, 1], [0, 1], color='royalblue', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate',fontsize=36)\n",
    "    plt.ylabel('True Positive Rate',fontsize=36)\n",
    "    plt.title('ex-VUS '+consType+ \" (n = \"+num+\")\", fontsize=36)\n",
    "    #plt.legend(fontsize=32,loc=4,facecolor='white', frameon=True, framealpha=1)\n",
    "    plt.legend(fontsize=32,loc=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to print AUC values for the different subsets\n",
    "def printAUC(tool, X,y,consType):\n",
    "    score_RF=clf_RF.predict_proba(tool)\n",
    "    score_RF\n",
    "    fpr_RF, tpr_RF, threshs = metrics.roc_curve(y,score_RF[:,1])\n",
    "    roc_auc_RF= auc(fpr_RF, tpr_RF)\n",
    "\n",
    "    score_SVM=svm_modelo.predict_proba(tool)\n",
    "    score_SVM\n",
    "    fpr_SVM, tpr_SVM, threshs = metrics.roc_curve(y,score_SVM[:,1])\n",
    "    roc_auc_SVM= auc(fpr_SVM, tpr_SVM)\n",
    "\n",
    "    red_probas = red_modelo.predict_proba(tool)\n",
    "    fpr_MLP, tpr_MLP, thresholds = metrics.roc_curve(y, red_probas)\n",
    "    roc_auc_mlp= auc(fpr_MLP, tpr_MLP)\n",
    "    print(consType, \"RF: \", roc_auc_RF, \" SVM: \", roc_auc_SVM, \" MLP: \", roc_auc_mlp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing AUC values from the different subsets\n",
    "printAUC(vint, X_int,y_int,'intron type')\n",
    "printAUC(miss, X_miss,y_miss,'missense')\n",
    "printAUC(nce, X_nce,y_nce,'non coding mRNA')\n",
    "printAUC(syn, X_syn, y_syn, 'synonymous')\n",
    "printAUC(oth, X_oth, y_oth, 'other types')\n",
    "printAUC(spl, X_spl, y_spl, ' splice variants')\n",
    "printAUC(indl, X_indl, y_indl, ' coding INDELs')\n",
    "printAUC(ign, X_ign, y_ign, 'intergenic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Values from the different subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotValues(vint, X_int,y_int,'intron type','349')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotValues(miss, X_miss,y_miss,'missense','2008')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotValues(nce, X_nce,y_nce,'non coding mRNA','340')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotValues(syn, X_syn, y_syn, 'synonymous','1844')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotValues(oth, X_oth, y_oth, 'other types','290')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotValues(spl, X_spl, y_spl, ' splice variants','475')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotValues(indl, X_indl, y_indl, ' coding INDELs', '69')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotValues(ign, X_ign, y_ign, 'intergenic', '151')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting classification of current VUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to process current VUS dataset\n",
    "def processModelVUS(df):\n",
    "    df['codon_degeneracy'] = df['codon_degeneracy'].str.split(',').str[0]\n",
    "    df['Consequence'] = df['Consequence'].str.split(',').str[0]\n",
    "    df = df.replace({'codon_degeneracy':'-'},0)\n",
    "    df=pd.get_dummies(df,columns=['Consequence'])\n",
    "    df = df.filter(['ada_score','AF','BLOSUM62','CADD_PHRED','codon_degeneracy','Eigen-pred_coding','GERP++_RS', \n",
    "              'integrated_fitCons_score','LoFtool','phyloP100way_vertebrate','SIFT', 'Consequence_5_prime_UTR_variant',\n",
    "              'Consequence_downstream_gene_variant', 'Consequence_frameshift_variant',\n",
    "              'Consequence_inframe_deletion', 'Consequence_inframe_insertion',\n",
    "              'Consequence_intron_variant', 'Consequence_missense_variant',\n",
    "              'Consequence_non_coding_transcript_exon_variant',\n",
    "              'Consequence_splice_donor_variant', 'Consequence_splice_region_variant',\n",
    "              'Consequence_start_lost', 'Consequence_stop_gained',\n",
    "              'Consequence_synonymous_variant', 'Consequence_upstream_gene_variant'])\n",
    "    df = df.replace({'ada_score': \"-\", 'AF': \"-\", 'CADD_PHRED':\"-\", 'Eigen-pred_coding': '-',\n",
    "               'integrated_fitCons_score': '-', 'LoFtool': '-', 'phyloP100way_vertebrate':'-',\n",
    "               'SIFT': '-'}, -1)\n",
    "    df = df.replace({'BLOSUM62':\"-\", 'GERP++_RS':'-'}, 0)\n",
    "    df = df.replace(\".\",0)   \n",
    "    df = df.astype(float)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1), copy=True)\n",
    "    scaler.fit (df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing current VUS dataset\n",
    "vus_model = processModelVUS(vus)\n",
    "vus_model = completeColumns(vus_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting classification of current VUS with the RF tool\n",
    "predict_RF_vus=clf_RF.predict(vus_model)\n",
    "predict_RF_vus\n",
    "\n",
    "arr=plt.hist(predict_RF_vus)\n",
    "for i in range(10):\n",
    "    plt.text(arr[1][i],arr[0][i],str(arr[0][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting classification of current VUS with the SVM tool\n",
    "predict_svm=svm_modelo.predict(vus_model)\n",
    "predict_svm\n",
    "\n",
    "arr=plt.hist(predict_svm)\n",
    "for i in range(10):\n",
    "    plt.text(arr[1][i],arr[0][i],str(arr[0][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting classification of current VUS with the MLP tool\n",
    "predict_red=red_modelo.predict_classes(vus_model)\n",
    "predict_red\n",
    "arr=plt.hist(predict_red)\n",
    "for i in range(10):\n",
    "    plt.text(arr[1][i],arr[0][i],str(arr[0][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting current VUS classification with the RF model\n",
    "score_RF_vus=clf_RF.predict_proba(vus_model)\n",
    "plt.figure(figsize=(15,12))\n",
    "plt.hist(score_RF_vus[:,1],bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot prediction of the RF model for missense variants from the current VUS set\n",
    "vus_miss =vus[(vus['REVEL_score']!= \"-\") & (vus['SIFT']!= \"-\") & (vus['PolyPhen']!= \"-\")]\n",
    "vus_miss = processModelVUS(vus_miss)\n",
    "vus_miss = completeColumns(vus_miss)\n",
    "score_RF_pred=clf_RF.predict_proba(vus_miss)\n",
    "plt.figure(figsize=(15,12))\n",
    "plt.hist(score_RF_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot prediction of the SVM model for missense variants from the current VUS set\n",
    "\n",
    "score_SVM_vus_miss=svm_modelo.predict_proba(vus_miss)\n",
    "score_SVM_vus_miss\n",
    "plt.figure(figsize=(15,12))\n",
    "plt.hist(score_SVM_vus_miss[:,1],bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot prediction of the MLP model for missense variants from the current VUS set\n",
    "\n",
    "score_MLP_vus_miss=red_modelo.predict_proba(vus_miss)\n",
    "score_MLP_vus_miss\n",
    "plt.figure(figsize=(15,12))\n",
    "plt.hist(score_MLP_vus_miss,bins=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
